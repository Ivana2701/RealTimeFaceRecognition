# Real-Time Face Detection and Recognition (Local)

A fully **local (offline)** Python application for real-time face detection and face recognition using a webcam. It uses **OpenCV** and **face_recognition** (dlib-based): no images or video are sent to any external service.

## Features

- **Enrollment**: Load images of known people from `data/known/`, compute face embeddings, store them in `data/encodings/encodings.pkl`.
- **Real-time recognition**: Read webcam frames, detect faces, compute embeddings, compare to the enrolled database.
- **Decision**: If the best match distance is below a configurable threshold, display that person’s name; otherwise display “Unknown”.
- **Visualization**: Bounding boxes around faces, labels (name or “Unknown”), and optional distance/confidence.
- **Controls**: `q` or ESC to quit, `r` to reload encodings from disk, `s` to save a snapshot.
- **TREZOR vault (access control demo)**: A second window shows a locked “vault”; it opens only when a configurable authorized identity (e.g. **Queen Elizabeth**) is recognized with sufficient confidence. See [TREZOR Vault (Access Control Demo)](#trezor-vault-access-control-demo).

## Requirements

- Python 3.8+
- Webcam
- **dlib** (required by `face_recognition`): can be tricky to install on some systems; see [Troubleshooting](#troubleshooting).

## Setup (Windows / macOS / Linux)

1. **Clone or download** this project and `cd` into it.

2. **Create a virtual environment** (recommended):

   ```bash
   python3 -m venv venv
   source venv/bin/activate   # macOS/Linux
   # or: venv\Scripts\activate   # Windows
   ```

3. **Install dependencies**:

   ```bash
   pip install -r requirements.txt
   ```

   If `face_recognition` (or `dlib`) fails to install:

   - **macOS**: `brew install cmake` then `pip install dlib` then `pip install face_recognition`.
   - **Windows**: Use a prebuilt wheel for dlib if available, or install Visual Studio Build Tools and build dlib from source.
   - **Linux**: `sudo apt-get install cmake` (and build-essential) then `pip install dlib face_recognition`.

   See [Troubleshooting](#troubleshooting) for more.

4. **Directory layout** (created automatically if missing when you run the scripts):

   ```
   data/
     known/           # One subfolder per person; folder name = label
       Person_1_Name/
         img1.jpg
       Queen Elizabeth/
         Queen-Elizabeth.webp
     encodings/
       encodings.pkl  # Generated by enroll.py
     snapshots/       # Optional; used when you press 's' in main.py
     test/
       video_frames/ # Optional; images for --no_camera simulation
   outputs/
     logs/
       vault_events.csv  # Created when vault opens/locks
   ```

## Adding Known People

1. Create a subfolder under `data/known/` named after the person (e.g. `data/known/Alice/`).
2. Put one or more photos of that person in the folder (`.jpg`, `.jpeg`, `.png`, `.bmp`, `.webp`).
3. **Rules**:
   - At least one clear face per image.
   - If an image has multiple faces, the **largest** face is used for enrollment.
   - Images with no detectable face are skipped (with a warning).

## Running Enrollment

Build or update the encodings database from `data/known/`:

```bash
python enroll.py
```

Options:

- `--known_dir data/known` — Root folder of known people (default).
- `--encodings_path data/encodings/encodings.pkl` — Output file (default).
- `--detection_model hog` — Use `hog` (faster) or `cnn` (more accurate, needs more CPU/GPU).
- `--no_incremental` — Rebuild from scratch instead of appending to existing encodings.

By default, enrollment is **incremental**: it loads existing encodings and adds new ones, skipping duplicates (same image path + file modified time).

## Running Real-Time Recognition

```bash
python main.py
```

Options:

- `--encodings_path data/encodings/encodings.pkl` — Encodings file (default).
- `--camera_index 0` — Webcam index (default 0).
- `--frame_width 640 --frame_height 480` — Resolution (smaller = faster).
- `--process_every_n_frames 3` — Run recognition every N frames (higher = faster, less responsive).
- `--threshold 0.6` — Match threshold; see [Threshold tuning](#threshold-tuning).
- `--detection_model hog` — Same as enrollment: `hog` or `cnn`.
- `--snapshot_dir data/snapshots` — Where to save snapshots when you press `s`.

If no encodings file exists or it is empty, the app runs in **detection-only** mode: all faces are labeled “Unknown”.

**Controls:**

- **q** or **ESC** — Quit (both camera and TREZOR windows close).
- **r** — Reload encodings from disk (hot reload after running `enroll.py` again).
- **s** — Save current frame to `snapshot_dir`.

## TREZOR Vault (Access Control Demo)

The app shows **two windows** at the same time:

1. **Camera – Face Recognition** — Live webcam feed with bounding boxes and names (“Unknown” if not recognized).
2. **TREZOR** — A vault/chest that is **closed and locked** by default and shows “ACCESS DENIED”.

The vault **opens** (shows gold and “ACCESS GRANTED”) only when the **authorized identity** is recognized with sufficient confidence (match distance ≤ threshold), and stays open for a short time after the person leaves (hold timer). Unknown faces and other known identities never open the vault.

**This is a visual demo only.** It is not a secure authentication product; use only for education and demos.

### Enrolling the authorized person (e.g. Queen Elizabeth)

The authorized identity is the **exact folder name** under `data/known/`. To use “Queen Elizabeth”:

1. Create folder: `data/known/Queen Elizabeth/`
2. Add one or more photos of that person:  
   `data/known/Queen Elizabeth/Queen-Elizabeth.webp` (or any `.jpg`, `.png`, etc.)
3. Run enrollment:

   ```bash
   python enroll.py
   ```

4. Run the app with that authorized name and a threshold:

   ```bash
   python main.py --authorized_name "Queen Elizabeth" --threshold 0.60
   ```

Vault options:

- `--authorized_name "Queen Elizabeth"` — Identity that can open the vault (default: `Queen Elizabeth`).
- `--vault_title TREZOR` — Vault window title (default: `TREZOR`).
- `--vault_open_hold_sec 3.0` — Seconds to keep vault open after the last authorized detection (default: 3.0).
- `--vault_hysteresis_frames 2` — Require this many consecutive recognition frames with the authorized person before opening (reduces flicker).
- `--vault_window_size 640x480` — Vault window size (e.g. `640x480`).
- `--no_vault_overlay_text` — Hide “LOCKED/OPEN” and “ACCESS DENIED/GRANTED” text on the vault window.

**Anti-flicker:** Opening requires the authorized person to be detected for `vault_hysteresis_frames` consecutive processed frames; after they leave, the vault stays open for `vault_open_hold_sec` seconds before locking again.

**Logging:** Vault open/lock events are written to `outputs/logs/vault_events.csv` (timestamp, event, authorized_name, reason, distance, camera_frame_id).

**Simulation without a webcam:** Use `--no_camera` and optionally put test images in `data/test/video_frames/`; the app will loop over those images instead of the camera.

### Privacy (offline, local)

- The system runs **entirely offline**; no network calls.
- Embeddings are stored locally in `data/encodings/encodings.pkl`; no biometric data is sent anywhere.

## Threshold Tuning

The **threshold** controls the trade-off between false accepts and false rejects:

- **Lower threshold** (e.g. 0.5) → fewer false accepts, more false rejects (more “Unknown”).
- **Higher threshold** (e.g. 0.65) → more accepts, higher risk of wrong identity.

**Suggested procedure:**

1. Start with **0.6** (default for `face_recognition`).
2. Try **0.55–0.65** and adjust based on your camera and lighting.
3. Test with:
   - Same person under different lighting.
   - Different people with similar appearance.
   - Unknown faces (should stay “Unknown”).

Tune so that known people are recognized reliably and unknowns are not accepted.

## Troubleshooting

### Camera not available

- Ensure no other app is using the webcam.
- Try `--camera_index 1` (or 2) if you have multiple cameras.
- On Linux, check permissions (e.g. `video` group).

### dlib / face_recognition install fails

- **macOS**: Install CMake and boost: `brew install cmake` (and optionally boost). Then `pip install dlib` then `pip install face_recognition`.
- **Windows**: Install [Visual Studio Build Tools](https://visualstudio.microsoft.com/visual-cpp-build-tools/) with “Desktop development with C++”. Then try `pip install dlib` and `face_recognition`. Alternatively, search for a prebuilt dlib wheel for your Python version.
- **Linux**: `sudo apt-get install build-essential cmake` and optionally `libopenblas-dev`. Then `pip install dlib face_recognition`.

### No faces found in images

- Use front-facing, well-lit photos with a clear single face.
- Supported formats: `.jpg`, `.jpeg`, `.png`, `.bmp`, `.webp`.
- If multiple faces: the largest face is used; avoid crowded photos if you want a specific person.

### Slow or laggy video

- Use `--process_every_n_frames 4` or `5`.
- Use `--frame_width 320 --frame_height 240`.
- Use `--detection_model hog` (default); `cnn` is heavier.

## Privacy and Ethics

- This is a **local demo** for **educational purposes**. All processing stays on your machine; no images or video are uploaded.
- **Use only with consent**: do not record or identify people without their knowledge and permission.
- **Store embeddings locally** and do not share the encodings file; biometric templates are sensitive and should be protected like passwords.
- Do not use this system for surveillance or access control without proper legal and ethical review.
- The TREZOR vault is a **demo** for access control visualization; it is not a secure authentication product.

## License

Use and modify as you like; ensure compliance with dlib/face_recognition and OpenCV licenses and with local laws regarding biometric data.
